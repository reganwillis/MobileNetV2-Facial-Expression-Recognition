{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceType":"datasetVersion","sourceId":1351797,"datasetId":786787,"databundleVersionId":1384195,"isSourceIdPinned":false}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# download dataset to file\n\nimport kagglehub\n# Download latest version\npath = kagglehub.dataset_download(\"msambare/fer2013\")\nprint(\"Path to dataset files:\", path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-02T20:46:42.637470Z","iopub.execute_input":"2025-06-02T20:46:42.637700Z","iopub.status.idle":"2025-06-02T20:46:43.242305Z","shell.execute_reply.started":"2025-06-02T20:46:42.637677Z","shell.execute_reply":"2025-06-02T20:46:43.241494Z"},"jupyter":{"source_hidden":true}},"outputs":[{"name":"stdout","text":"Path to dataset files: /kaggle/input/fer2013\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\nimport cv2\nimport torch\nfrom torchinfo import summary\nfrom matplotlib import pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom transformers.models.mobilenet_v2 import MobileNetV2Model\nfrom transformers.models.mobilenet_v2 import MobileNetV2PreTrainedModel\nfrom transformers.models.mobilenet_v2.configuration_mobilenet_v2 import MobileNetV2Config","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-02T20:46:43.244398Z","iopub.execute_input":"2025-06-02T20:46:43.244681Z","iopub.status.idle":"2025-06-02T20:47:21.313596Z","shell.execute_reply.started":"2025-06-02T20:46:43.244659Z","shell.execute_reply":"2025-06-02T20:47:21.313006Z"}},"outputs":[{"name":"stderr","text":"2025-06-02 20:47:04.966334: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1748897225.383812      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1748897225.501896      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# constants\nDEBUG = True\nPRETRAINED_CONFIG = ''\n# https://huggingface.co/google/mobilenet_v2_1.4_224\nPRETRAINED_MODEL = 'google/mobilenet_v2_1.4_224'\n#cfg = MobileNetV2Config(PRETRAINED_CONFIG)\ncfg = MobileNetV2Config()\nBATCH_SIZE = 32\nNUM_EPOCHS = 20\n\nif not torch.cuda.is_available():\n    print('GPU not available, running script on CPU..')\nDEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-02T20:47:21.314547Z","iopub.execute_input":"2025-06-02T20:47:21.314993Z","iopub.status.idle":"2025-06-02T20:47:21.320359Z","shell.execute_reply.started":"2025-06-02T20:47:21.314974Z","shell.execute_reply":"2025-06-02T20:47:21.319541Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom PIL import Image\nimport torchvision.transforms as transforms\nclass FERDataset(torch.utils.data.Dataset):\n    # https://www.kaggle.com/datasets/msambare/fer2013\n    def __init__(self, images, labels):\n        self.images = images\n        self.labels = labels\n        self.transform = self._transform\n        self.target_transform = self._target_transform\n        self.class_map_loaded = {\n            'angry': 0,\n            'disgust': 1,\n            'fear': 2,\n            'happy': 3,\n            'neutral': 4,\n            'sad': 5,\n            'surprise': 6\n        }\n        self.class_map = {\n            0: 'positive',\n            1: 'negative',\n            2: 'neutral'\n        }\n        self.NUM_CLASSES = len(self.class_map)\n\n    def __len__(self):\n        return len(self.images)\n\n    def __getitem__(self, idx):\n        image = self.images[idx]\n        image = self.transform(image)\n        label = self.labels[idx]\n        label = self.target_transform(label)\n\n        return image, label\n\n    def _transform(self, image):\n        image = cv2.imread(image)\n        #image_array = np.array(image).reshape(3, 48, 48)#.astype(np.uint8)\n        image = Image.fromarray(image)\n        #image = torch.from_numpy(image)\n        image = transforms.functional.pil_to_tensor(image)\n        normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.299, 0.224, 0.225])\n        image = normalize(image/255.0)\n\n        return image\n\n    def _target_transform(self, target):\n        # TODO: map to new class map\n        target = self.class_map_loaded[target]\n        return int(target)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-02T20:47:21.321211Z","iopub.execute_input":"2025-06-02T20:47:21.321645Z","iopub.status.idle":"2025-06-02T20:47:21.386742Z","shell.execute_reply.started":"2025-06-02T20:47:21.321601Z","shell.execute_reply":"2025-06-02T20:47:21.386158Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# load dataset into script\nprint('loading dataset from file...')\n\ntrain_images = []\ntrain_labels = []\nfor subdir in os.listdir(path+'/train'):\n    for idx in os.listdir(path+'/train/'+subdir):\n        train_images.append(path+'/train/'+subdir+'/'+idx)\n        train_labels.append(subdir)\n        #if DEBUG:\n        #    print(path+'/train/'+subdir+'/'+idx)\n        #   print(subdir)\n\ntest_images = []\ntest_labels = []\nfor subdir in os.listdir(path+'/test'):\n    for idx in os.listdir(path+'/test/'+subdir):\n        test_images.append(path+'/test/'+subdir+'/'+idx)\n        test_labels.append(subdir)\nprint('...done')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-02T20:47:21.387549Z","iopub.execute_input":"2025-06-02T20:47:21.387775Z","iopub.status.idle":"2025-06-02T20:47:22.137094Z","shell.execute_reply.started":"2025-06-02T20:47:21.387760Z","shell.execute_reply":"2025-06-02T20:47:22.136438Z"},"jupyter":{"source_hidden":true}},"outputs":[{"name":"stdout","text":"loading dataset from file...\n...done\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# create dataloaders\nx_train, x_val, y_train, y_val = train_test_split(train_images, train_labels, test_size=0.2)\n\nif DEBUG:\n    for i in range(0, 10):\n        print(x_val[i], '|', y_val[i])\n\ntrain_dataset = FERDataset(x_train, y_train)\nval_dataset = FERDataset(x_val, y_val)\ntest_dataset = FERDataset(test_images, test_labels)\n\ntrain_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\nval_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\ntest_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-02T20:47:22.138022Z","iopub.execute_input":"2025-06-02T20:47:22.138301Z","iopub.status.idle":"2025-06-02T20:47:22.164770Z","shell.execute_reply.started":"2025-06-02T20:47:22.138279Z","shell.execute_reply":"2025-06-02T20:47:22.164178Z"},"jupyter":{"source_hidden":true}},"outputs":[{"name":"stdout","text":"/kaggle/input/fer2013/train/sad/Training_91601928.jpg | sad\n/kaggle/input/fer2013/train/angry/Training_68690730.jpg | angry\n/kaggle/input/fer2013/train/surprise/Training_39536730.jpg | surprise\n/kaggle/input/fer2013/train/sad/Training_73882625.jpg | sad\n/kaggle/input/fer2013/train/happy/Training_68928178.jpg | happy\n/kaggle/input/fer2013/train/sad/Training_47927277.jpg | sad\n/kaggle/input/fer2013/train/fear/Training_36695436.jpg | fear\n/kaggle/input/fer2013/train/happy/Training_70930673.jpg | happy\n/kaggle/input/fer2013/train/happy/Training_61616531.jpg | happy\n/kaggle/input/fer2013/train/neutral/Training_13306740.jpg | neutral\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"if DEBUG:\n    for i, (image, label) in enumerate(test_dataloader):\n        for j in range(BATCH_SIZE):\n            pass\n            #print('Label:', label[j])\n            #plt.imshow(image[j].permute(1, 2, 0))\n            #plt.show()\n        break","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-02T20:47:22.167229Z","iopub.execute_input":"2025-06-02T20:47:22.167440Z","iopub.status.idle":"2025-06-02T20:47:23.021809Z","shell.execute_reply.started":"2025-06-02T20:47:22.167424Z","shell.execute_reply":"2025-06-02T20:47:23.020929Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"class MobileNetV2ForFacialExpressionRecognition(MobileNetV2PreTrainedModel):\n    \"\"\"\n    from MobileNetV2 for image classification\n    \"\"\"\n    def __init__(self, config):\n        super().__init__(config=config)\n\n        self.num_labels = 3\n        self.mobilenet_v2 = MobileNetV2Model(config)\n\n        last_hidden_size = self.mobilenet_v2.conv_1x1.convolution.out_channels\n\n        # Classifier head\n        self.dropout = torch.nn.Dropout(config.classifier_dropout_prob, inplace=True)\n        self.classifier = torch.nn.Linear(last_hidden_size, config.num_labels)\n\n        # Initialize weights and apply final processing\n        self.post_init()\n\n    def forward(self, pixel_values=None, output_hidden_states=None, labels=None):\n        outputs = self.mobilenet_v2(pixel_values, output_hidden_states=output_hidden_states)\n        pooled_output = outputs[1]\n        logits = self.classifier(self.dropout(pooled_output))\n\n        loss = None\n        if labels is not None:\n            self.config.problem_type = \"multi_label_classification\"\n            loss_fct = BCEWithLogitsLoss()\n            loss = loss_fct(logits, labels)\n        output = (logits,) + outputs[2:]\n        return ((loss,) + output) if loss is not None else output","metadata":{"trusted":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2025-06-02T20:47:23.022981Z","iopub.execute_input":"2025-06-02T20:47:23.023825Z","iopub.status.idle":"2025-06-02T20:47:23.030089Z","shell.execute_reply.started":"2025-06-02T20:47:23.023786Z","shell.execute_reply":"2025-06-02T20:47:23.029575Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"print('...creating MobileNetV2 model')\nmodel = MobileNetV2ForFacialExpressionRecognition(cfg).from_pretrained(PRETRAINED_MODEL)\nmodel.to(DEVICE)\nsummary(model, input_size=(BATCH_SIZE, 3, 48, 48))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-02T20:47:23.031057Z","iopub.execute_input":"2025-06-02T20:47:23.031360Z","iopub.status.idle":"2025-06-02T20:47:26.060696Z","shell.execute_reply.started":"2025-06-02T20:47:23.031334Z","shell.execute_reply":"2025-06-02T20:47:26.060007Z"}},"outputs":[{"name":"stdout","text":"...creating MobileNetV2 model\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/69.8k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e66a768ebfba4357add4847d382d397b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/24.7M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cc92e08478d54cd5875a9ebeca8ca1e4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/24.7M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f66563f7b61c47dd97b690de84c44a57"}},"metadata":{}},{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"====================================================================================================\nLayer (type:depth-idx)                             Output Shape              Param #\n====================================================================================================\nMobileNetV2ForFacialExpressionRecognition          [32, 1001]                --\n├─MobileNetV2Model: 1-1                            [32, 1792]                --\n│    └─MobileNetV2Stem: 2-1                        [32, 24, 24, 24]          --\n│    │    └─MobileNetV2ConvLayer: 3-1              [32, 48, 24, 24]          1,392\n│    │    └─MobileNetV2ConvLayer: 3-2              [32, 48, 24, 24]          528\n│    │    └─MobileNetV2ConvLayer: 3-3              [32, 24, 24, 24]          1,200\n│    └─ModuleList: 2-2                             --                        --\n│    │    └─MobileNetV2InvertedResidual: 3-4       [32, 32, 12, 12]          10,000\n│    │    └─MobileNetV2InvertedResidual: 3-5       [32, 32, 12, 12]          14,848\n│    │    └─MobileNetV2InvertedResidual: 3-6       [32, 48, 6, 6]            17,952\n│    │    └─MobileNetV2InvertedResidual: 3-7       [32, 48, 6, 6]            31,488\n│    │    └─MobileNetV2InvertedResidual: 3-8       [32, 48, 6, 6]            31,488\n│    │    └─MobileNetV2InvertedResidual: 3-9       [32, 88, 3, 3]            43,088\n│    │    └─MobileNetV2InvertedResidual: 3-10      [32, 88, 3, 3]            99,968\n│    │    └─MobileNetV2InvertedResidual: 3-11      [32, 88, 3, 3]            99,968\n│    │    └─MobileNetV2InvertedResidual: 3-12      [32, 88, 3, 3]            99,968\n│    │    └─MobileNetV2InvertedResidual: 3-13      [32, 136, 3, 3]           125,408\n│    │    └─MobileNetV2InvertedResidual: 3-14      [32, 136, 3, 3]           232,832\n│    │    └─MobileNetV2InvertedResidual: 3-15      [32, 136, 3, 3]           232,832\n│    │    └─MobileNetV2InvertedResidual: 3-16      [32, 224, 2, 2]           304,816\n│    │    └─MobileNetV2InvertedResidual: 3-17      [32, 224, 2, 2]           620,032\n│    │    └─MobileNetV2InvertedResidual: 3-18      [32, 224, 2, 2]           620,032\n│    │    └─MobileNetV2InvertedResidual: 3-19      [32, 448, 2, 2]           921,536\n│    └─MobileNetV2ConvLayer: 2-3                   [32, 1792, 2, 2]          --\n│    │    └─Conv2d: 3-20                           [32, 1792, 2, 2]          802,816\n│    │    └─BatchNorm2d: 3-21                      [32, 1792, 2, 2]          3,584\n│    │    └─ReLU6: 3-22                            [32, 1792, 2, 2]          --\n│    └─AdaptiveAvgPool2d: 2-4                      [32, 1792, 1, 1]          --\n├─Dropout: 1-2                                     [32, 1792]                --\n├─Linear: 1-3                                      [32, 1001]                1,794,793\n====================================================================================================\nTotal params: 6,110,569\nTrainable params: 6,110,569\nNon-trainable params: 0\nTotal mult-adds (Units.GIGABYTES): 1.09\n====================================================================================================\nInput size (MB): 0.88\nForward/backward pass size (MB): 235.90\nParams size (MB): 24.44\nEstimated Total Size (MB): 261.22\n===================================================================================================="},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"# loss function & optimizer\ndef loss_fn(outputs, targets):\n    return torch.nn.CrossEntropyLoss()(outputs, targets)\n\noptimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9, weight_decay=0.0001)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-02T20:47:26.061445Z","iopub.execute_input":"2025-06-02T20:47:26.061679Z","iopub.status.idle":"2025-06-02T20:47:26.066339Z","shell.execute_reply.started":"2025-06-02T20:47:26.061662Z","shell.execute_reply":"2025-06-02T20:47:26.065794Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"# compute accuracy\ndef compute_accuracy(outputs, targets):\n    predictions = torch.argmax(outputs, 1)\n    num_predictions = len(predictions)\n\n    predictions = predictions.cpu()\n    targets = targets.cpu()\n    num_incorrect = 0\n    for i in range(len(predictions)):\n        if not predictions[i] == targets[i]:\n            num_incorrect = num_incorrect + 1\n    accuracy = (num_predictions-num_incorrect)/num_predictions\n\n    return accuracy","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-02T20:47:26.067050Z","iopub.execute_input":"2025-06-02T20:47:26.067333Z","iopub.status.idle":"2025-06-02T20:47:26.089588Z","shell.execute_reply.started":"2025-06-02T20:47:26.067315Z","shell.execute_reply":"2025-06-02T20:47:26.089080Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"# TODO: train function\ndef train(model, dataloader, device, epoch, num_epochs, total_steps):\n    running_loss = 0.0\n    running_acc = 0.0\n    model.train()\n\n    for i, (images, labels) in enumerate(dataloader):\n        images = images.to(device)\n        targets = labels.to(device)\n\n        outputs = model(images)\n        outputs = outputs[0]\n\n        loss = loss_fn(outputs, targets)\n        accuracy = compute_accuracy(outputs, targets)\n        \n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item()\n        running_acc += accuracy\n\n        if (i+1) % 50 == 0:\n            print(\n                f'TRAINING --> Epoch: {epoch+1}/{num_epochs}, ' +\n                f'Step: {i+1}/{total_steps}, ' +\n                f'Loss: {running_loss / (i+1)}, '\n                f'Accuracy: {running_acc / (i+1)}'\n            )\n    \n    running_loss = running_loss / total_steps\n    running_acc = running_acc / total_steps\n\n    return running_loss, running_acc","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-02T20:47:26.090266Z","iopub.execute_input":"2025-06-02T20:47:26.090466Z","iopub.status.idle":"2025-06-02T20:47:26.116343Z","shell.execute_reply.started":"2025-06-02T20:47:26.090451Z","shell.execute_reply":"2025-06-02T20:47:26.115833Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"# TODO: validate function\ndef validate(model, dataloader, device, epoch, num_epochs, total_steps):\n    running_loss = 0.0\n    running_acc = 0.0\n    model.eval()\n\n    with torch.no_grad():\n        for i, (images, labels) in enumerate(dataloader):\n            images = images.to(device)\n            targets = labels.to(device)\n    \n            outputs = model(images)\n            outputs = outputs[0]\n    \n            loss = loss_fn(outputs, targets)\n            accuracy = compute_accuracy(outputs, targets)\n    \n            running_loss += loss.item()\n            running_acc += accuracy\n    \n            if (i+1) % 50 == 0:\n                print(\n                    f'TRAINING --> Epoch: {epoch+1}/{num_epochs}, ' +\n                    f'Step: {i+1}/{total_steps}, ' +\n                    f'Loss: {running_loss / (i+1)}, '\n                    f'Accuracy: {running_acc / (i+1)}'\n                )\n    \n    running_loss = running_loss / total_steps\n    running_acc = running_acc / total_steps\n\n    return running_loss, running_acc","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-02T20:47:26.116952Z","iopub.execute_input":"2025-06-02T20:47:26.117195Z","iopub.status.idle":"2025-06-02T20:47:26.133133Z","shell.execute_reply.started":"2025-06-02T20:47:26.117176Z","shell.execute_reply":"2025-06-02T20:47:26.132638Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"def save_best_model(\n    model: torch.nn.Module,\n    model_save_path,\n    val_loss: float,\n    val_losses: list,\n    epoch: int,\n    keep_models: bool = False\n):\n    \"\"\"Save the model if it is the first epoch. Subsequently, save the model\n    only if a lower validation loss is achieved whilst training.\n\n    :param model: The model to save.\n    :type model: torch.nn.Module\n    :param model_save_path: The location to save the model to.\n    :type model_save_path: Path\n    :param val_loss: The current epoch's validation loss.\n    :type val_loss: float\n    :param val_losses: The history of all other validation losses.\n    :type val_losses: list\n    :param epoch: The current epoch number.\n    :type epoch: int\n    :param keep_models: Should all models be saved, defaults to False\n    :type keep_models: bool, optional\n    \"\"\"\n    # Should we keep all models or just one\n    if keep_models:\n        model_save_path = model_save_path / f'model_{epoch+1}_{val_loss}.pt'\n    else:\n        model_save_path = model_save_path / f'model_state_dict.pt'\n    # Save the first model\n    if len(val_losses) == 0:\n        torch.save(\n            model.state_dict(),\n            model_save_path\n        )\n        print(\n            'SAVING --> First epoch: \\n' +\n            f'Val Loss: {val_loss}\\n' +\n            f'Saving new model to:\\n{model_save_path}'\n        )\n    elif val_loss < min(val_losses):\n        # If our new validation loss is less than the previous best save the\n        # model\n        print(\n            'SAVING --> Found model with better validation loss: \\n' +\n            f'New Best Val Loss: {val_loss}\\n' +\n            f'Old Best Val Loss: {min(val_losses)}\\n'\n            f'Saving new model to:\\n{model_save_path}'\n        )\n        torch.save(\n            model.state_dict(),\n            model_save_path\n        )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-02T20:47:26.133810Z","iopub.execute_input":"2025-06-02T20:47:26.133995Z","iopub.status.idle":"2025-06-02T20:47:26.159014Z","shell.execute_reply.started":"2025-06-02T20:47:26.133981Z","shell.execute_reply":"2025-06-02T20:47:26.158505Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"def plot_epoch_metrics(x, y, data_names, title_prefix, yaxis_label):\n    \"\"\"Plot metrics with the number of epochs on the x axis and the metric of\n    interest on the y axis. Note that this function differs based on the input.\n\n    :param x: The values to use on the x-axis.\n    :type x: list\n    :param y: A list of lists containing len(x) data points to plot. The inner\n        lists are the different series to plot.\n    :type y: list\n    :param data_names: Names of the series to use in the legend.\n    :type data_names: str\n    :param title_prefix: A prefix to add before everything else in the title.\n    :type title_prefix: str\n    :param yaxis_label: The label for the y axis.\n    :type yaxis_label: str\n    \"\"\"\n    # Plot multiple series of data\n    for i in y:\n        plt.plot(x, i)\n    # Set the title\n    plt.title(title_prefix + ' ' + ' vs. '.join(data_names) + ' ' + yaxis_label)\n    # Set the y axis label\n    plt.ylabel(yaxis_label)\n    # Enable the legend with the appropriate names\n    plt.legend(data_names)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-02T20:47:26.159687Z","iopub.execute_input":"2025-06-02T20:47:26.159872Z","iopub.status.idle":"2025-06-02T20:47:26.180444Z","shell.execute_reply.started":"2025-06-02T20:47:26.159859Z","shell.execute_reply":"2025-06-02T20:47:26.179897Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"# TODO: train_loop\nfrom pathlib import Path\ndef train_loop(model, train_dataloader, val_dataloader, device, num_epochs, model_save_path=Path('./models')):\n    print(f'Models will be saved to: {model_save_path}')\n    train_losses = []\n    train_accs = []\n    val_losses = []\n    val_accs = []\n\n    if not model_save_path.exists():\n        model_save_path.mkdir(exist_ok=True, parents=True)\n\n    train_total_steps = len(train_dataloader)\n    val_total_steps = len(val_dataloader)\n\n    for epoch in range(num_epochs):\n        train_loss, train_accuracy = train(model, train_dataloader, device, epoch, num_epochs, train_total_steps)\n        print(\n            f'TRAINING --> Epoch {epoch+1}/{NUM_EPOCHS} DONE, ' +\n            f'Avg Loss: {train_loss}, Avg Accuracy: {train_accuracy}'\n        )\n\n        val_loss, val_accuracy = validate(model, val_dataloader, device, epoch, num_epochs, val_total_steps)\n        print(\n            f'VALIDATION --> Epoch {epoch+1}/{NUM_EPOCHS} DONE, ' +\n            f'Avg Loss: {val_loss}, Avg Accuracy: {val_accuracy}'\n        )\n\n        save_best_model(model, model_save_path, val_loss, val_losses, epoch)\n        \n        train_losses.append(train_loss)\n        train_accs.append(train_accuracy)\n        val_losses.append(val_loss)\n        val_accs.append(val_accuracy)\n    return (train_losses, train_accs), (val_losses, val_accs)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-02T20:47:26.181123Z","iopub.execute_input":"2025-06-02T20:47:26.181355Z","iopub.status.idle":"2025-06-02T20:47:26.203089Z","shell.execute_reply.started":"2025-06-02T20:47:26.181339Z","shell.execute_reply":"2025-06-02T20:47:26.202507Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"# TODO: run training\nprint('training..')\n(train_losses, train_accs), (val_losses, val_accs) = train_loop(model, train_dataloader, val_dataloader, DEVICE, NUM_EPOCHS)\nprint(f'Best Validation Loss: {min(val_losses)} after epoch {np.argmin(val_losses) + 1}')\nprint(f'Best Validation Acc: {max(val_accs)} after epoch {np.argmax(val_accs) + 1}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-02T20:47:26.203937Z","iopub.execute_input":"2025-06-02T20:47:26.204196Z","iopub.status.idle":"2025-06-02T20:57:50.446065Z","shell.execute_reply.started":"2025-06-02T20:47:26.204170Z","shell.execute_reply":"2025-06-02T20:57:50.445257Z"},"jupyter":{"source_hidden":true}},"outputs":[{"name":"stdout","text":"training..\nModels will be saved to: models\nTRAINING --> Epoch: 1/20, Step: 50/718, Loss: 4.889138627052307, Accuracy: 0.145625\nTRAINING --> Epoch: 1/20, Step: 100/718, Loss: 3.608825000524521, Accuracy: 0.201875\nTRAINING --> Epoch: 1/20, Step: 150/718, Loss: 3.08474237203598, Accuracy: 0.221875\nTRAINING --> Epoch: 1/20, Step: 200/718, Loss: 2.780789623260498, Accuracy: 0.25171875\nTRAINING --> Epoch: 1/20, Step: 250/718, Loss: 2.5841137681007385, Accuracy: 0.2695\nTRAINING --> Epoch: 1/20, Step: 300/718, Loss: 2.436947689851125, Accuracy: 0.2886458333333333\nTRAINING --> Epoch: 1/20, Step: 350/718, Loss: 2.3250735201154438, Accuracy: 0.3020535714285714\nTRAINING --> Epoch: 1/20, Step: 400/718, Loss: 2.2369857713580132, Accuracy: 0.30984375\nTRAINING --> Epoch: 1/20, Step: 450/718, Loss: 2.167528333399031, Accuracy: 0.3176388888888889\nTRAINING --> Epoch: 1/20, Step: 500/718, Loss: 2.1086384348869323, Accuracy: 0.327375\nTRAINING --> Epoch: 1/20, Step: 550/718, Loss: 2.058986300988631, Accuracy: 0.3351136363636364\nTRAINING --> Epoch: 1/20, Step: 600/718, Loss: 2.019084141254425, Accuracy: 0.34057291666666667\nTRAINING --> Epoch: 1/20, Step: 650/718, Loss: 1.979373117043422, Accuracy: 0.3476442307692308\nTRAINING --> Epoch: 1/20, Step: 700/718, Loss: 1.9429493001529148, Accuracy: 0.3532142857142857\nTRAINING --> Epoch 1/20 DONE, Avg Loss: 1.9292132228529886, Avg Accuracy: 0.355915813854911\nTRAINING --> Epoch: 1/20, Step: 50/180, Loss: 1.5058632731437682, Accuracy: 0.449375\nTRAINING --> Epoch: 1/20, Step: 100/180, Loss: 1.4844264602661132, Accuracy: 0.45\nTRAINING --> Epoch: 1/20, Step: 150/180, Loss: 1.4813847756385803, Accuracy: 0.45666666666666667\nVALIDATION --> Epoch 1/20 DONE, Avg Loss: 1.4800360040532219, Avg Accuracy: 0.4563244047619048\nSAVING --> First epoch: \nVal Loss: 1.4800360040532219\nSaving new model to:\nmodels/model_state_dict.pt\nTRAINING --> Epoch: 2/20, Step: 50/718, Loss: 1.413508243560791, Accuracy: 0.485\nTRAINING --> Epoch: 2/20, Step: 100/718, Loss: 1.3994458532333374, Accuracy: 0.481875\nTRAINING --> Epoch: 2/20, Step: 150/718, Loss: 1.3890310581525167, Accuracy: 0.48\nTRAINING --> Epoch: 2/20, Step: 200/718, Loss: 1.3947375506162643, Accuracy: 0.478125\nTRAINING --> Epoch: 2/20, Step: 250/718, Loss: 1.3917580485343932, Accuracy: 0.475125\nTRAINING --> Epoch: 2/20, Step: 300/718, Loss: 1.3811903349558512, Accuracy: 0.4771875\nTRAINING --> Epoch: 2/20, Step: 350/718, Loss: 1.3779706507069724, Accuracy: 0.4772321428571429\nTRAINING --> Epoch: 2/20, Step: 400/718, Loss: 1.3672395004332065, Accuracy: 0.480703125\nTRAINING --> Epoch: 2/20, Step: 450/718, Loss: 1.3662673072020213, Accuracy: 0.4801388888888889\nTRAINING --> Epoch: 2/20, Step: 500/718, Loss: 1.3589561349153518, Accuracy: 0.48275\nTRAINING --> Epoch: 2/20, Step: 550/718, Loss: 1.356772378249602, Accuracy: 0.48414772727272726\nTRAINING --> Epoch: 2/20, Step: 600/718, Loss: 1.3556257917483647, Accuracy: 0.48322916666666665\nTRAINING --> Epoch: 2/20, Step: 650/718, Loss: 1.3482537849132832, Accuracy: 0.4858653846153846\nTRAINING --> Epoch: 2/20, Step: 700/718, Loss: 1.3461020701272146, Accuracy: 0.48642857142857143\nTRAINING --> Epoch 2/20 DONE, Avg Loss: 1.3443696806025704, Avg Accuracy: 0.4870431906261354\nTRAINING --> Epoch: 2/20, Step: 50/180, Loss: 1.3617365121841432, Accuracy: 0.478125\nTRAINING --> Epoch: 2/20, Step: 100/180, Loss: 1.3551689016819, Accuracy: 0.480625\nTRAINING --> Epoch: 2/20, Step: 150/180, Loss: 1.3593201486269633, Accuracy: 0.4775\nVALIDATION --> Epoch 2/20 DONE, Avg Loss: 1.3568388243516287, Avg Accuracy: 0.4771329365079365\nSAVING --> Found model with better validation loss: \nNew Best Val Loss: 1.3568388243516287\nOld Best Val Loss: 1.4800360040532219\nSaving new model to:\nmodels/model_state_dict.pt\nTRAINING --> Epoch: 3/20, Step: 50/718, Loss: 1.1655388653278351, Accuracy: 0.550625\nTRAINING --> Epoch: 3/20, Step: 100/718, Loss: 1.171846798658371, Accuracy: 0.5609375\nTRAINING --> Epoch: 3/20, Step: 150/718, Loss: 1.1780375703175863, Accuracy: 0.5566666666666666\nTRAINING --> Epoch: 3/20, Step: 200/718, Loss: 1.1847424003481866, Accuracy: 0.55\nTRAINING --> Epoch: 3/20, Step: 250/718, Loss: 1.190291438817978, Accuracy: 0.547625\nTRAINING --> Epoch: 3/20, Step: 300/718, Loss: 1.1833572844664255, Accuracy: 0.54875\nTRAINING --> Epoch: 3/20, Step: 350/718, Loss: 1.1824440213612148, Accuracy: 0.5508035714285714\nTRAINING --> Epoch: 3/20, Step: 400/718, Loss: 1.1814110369980335, Accuracy: 0.5528125\nTRAINING --> Epoch: 3/20, Step: 450/718, Loss: 1.1830931301911671, Accuracy: 0.551875\nTRAINING --> Epoch: 3/20, Step: 500/718, Loss: 1.183381254196167, Accuracy: 0.5523125\nTRAINING --> Epoch: 3/20, Step: 550/718, Loss: 1.1834805313023653, Accuracy: 0.5515909090909091\nTRAINING --> Epoch: 3/20, Step: 600/718, Loss: 1.1848790489633878, Accuracy: 0.5505208333333333\nTRAINING --> Epoch: 3/20, Step: 650/718, Loss: 1.1861662046725934, Accuracy: 0.5505769230769231\nTRAINING --> Epoch: 3/20, Step: 700/718, Loss: 1.1870308659757887, Accuracy: 0.5511160714285714\nTRAINING --> Epoch 3/20 DONE, Avg Loss: 1.187625686355288, Avg Accuracy: 0.551240614024464\nTRAINING --> Epoch: 3/20, Step: 50/180, Loss: 1.3250840878486634, Accuracy: 0.513125\nTRAINING --> Epoch: 3/20, Step: 100/180, Loss: 1.2944768732786178, Accuracy: 0.5246875\nTRAINING --> Epoch: 3/20, Step: 150/180, Loss: 1.3112229947249094, Accuracy: 0.5204166666666666\nVALIDATION --> Epoch 3/20 DONE, Avg Loss: 1.3026021225584878, Avg Accuracy: 0.5242807539682539\nSAVING --> Found model with better validation loss: \nNew Best Val Loss: 1.3026021225584878\nOld Best Val Loss: 1.3568388243516287\nSaving new model to:\nmodels/model_state_dict.pt\nTRAINING --> Epoch: 4/20, Step: 50/718, Loss: 1.0634426593780517, Accuracy: 0.60875\nTRAINING --> Epoch: 4/20, Step: 100/718, Loss: 1.0390381503105164, Accuracy: 0.6121875\nTRAINING --> Epoch: 4/20, Step: 150/718, Loss: 1.033362028201421, Accuracy: 0.611875\nTRAINING --> Epoch: 4/20, Step: 200/718, Loss: 1.0380075785517693, Accuracy: 0.60828125\nTRAINING --> Epoch: 4/20, Step: 250/718, Loss: 1.050878385782242, Accuracy: 0.605625\nTRAINING --> Epoch: 4/20, Step: 300/718, Loss: 1.0529251531759898, Accuracy: 0.6034375\nTRAINING --> Epoch: 4/20, Step: 350/718, Loss: 1.0601607147284917, Accuracy: 0.6023214285714286\nTRAINING --> Epoch: 4/20, Step: 400/718, Loss: 1.0597962337732314, Accuracy: 0.603125\nTRAINING --> Epoch: 4/20, Step: 450/718, Loss: 1.0687967292467753, Accuracy: 0.5979166666666667\nTRAINING --> Epoch: 4/20, Step: 500/718, Loss: 1.0738454043865204, Accuracy: 0.5958125\nTRAINING --> Epoch: 4/20, Step: 550/718, Loss: 1.0761451859907671, Accuracy: 0.5939204545454545\nTRAINING --> Epoch: 4/20, Step: 600/718, Loss: 1.0754541106025377, Accuracy: 0.5934375\nTRAINING --> Epoch: 4/20, Step: 650/718, Loss: 1.0779346377115984, Accuracy: 0.593173076923077\nTRAINING --> Epoch: 4/20, Step: 700/718, Loss: 1.0773166997943606, Accuracy: 0.5935714285714285\nTRAINING --> Epoch 4/20 DONE, Avg Loss: 1.076757352166189, Avg Accuracy: 0.5941530670945865\nTRAINING --> Epoch: 4/20, Step: 50/180, Loss: 1.243964467048645, Accuracy: 0.550625\nTRAINING --> Epoch: 4/20, Step: 100/180, Loss: 1.231687024831772, Accuracy: 0.5478125\nTRAINING --> Epoch: 4/20, Step: 150/180, Loss: 1.2229075129826863, Accuracy: 0.5541666666666667\nVALIDATION --> Epoch 4/20 DONE, Avg Loss: 1.2301086044973797, Avg Accuracy: 0.5506200396825397\nSAVING --> Found model with better validation loss: \nNew Best Val Loss: 1.2301086044973797\nOld Best Val Loss: 1.3026021225584878\nSaving new model to:\nmodels/model_state_dict.pt\nTRAINING --> Epoch: 5/20, Step: 50/718, Loss: 0.9516086387634277, Accuracy: 0.6375\nTRAINING --> Epoch: 5/20, Step: 100/718, Loss: 0.9389283084869384, Accuracy: 0.643125\nTRAINING --> Epoch: 5/20, Step: 150/718, Loss: 0.942379717429479, Accuracy: 0.6427083333333333\nTRAINING --> Epoch: 5/20, Step: 200/718, Loss: 0.9559978929162025, Accuracy: 0.6365625\nTRAINING --> Epoch: 5/20, Step: 250/718, Loss: 0.9706958694458008, Accuracy: 0.631\nTRAINING --> Epoch: 5/20, Step: 300/718, Loss: 0.9700126785039902, Accuracy: 0.6323958333333334\nTRAINING --> Epoch: 5/20, Step: 350/718, Loss: 0.9712920263835362, Accuracy: 0.6326785714285714\nTRAINING --> Epoch: 5/20, Step: 400/718, Loss: 0.9730431355535984, Accuracy: 0.631953125\nTRAINING --> Epoch: 5/20, Step: 450/718, Loss: 0.9785869264602661, Accuracy: 0.6298611111111111\nTRAINING --> Epoch: 5/20, Step: 500/718, Loss: 0.9781455537080764, Accuracy: 0.6314375\nTRAINING --> Epoch: 5/20, Step: 550/718, Loss: 0.9828464175354351, Accuracy: 0.6295454545454545\nTRAINING --> Epoch: 5/20, Step: 600/718, Loss: 0.9865809881687164, Accuracy: 0.6283854166666667\nTRAINING --> Epoch: 5/20, Step: 650/718, Loss: 0.9935256677407485, Accuracy: 0.6252403846153847\nTRAINING --> Epoch: 5/20, Step: 700/718, Loss: 1.0084961697884969, Accuracy: 0.6199553571428571\nTRAINING --> Epoch 5/20 DONE, Avg Loss: 1.0126977083078665, Avg Accuracy: 0.6181705673973599\nTRAINING --> Epoch: 5/20, Step: 50/180, Loss: 1.305657823085785, Accuracy: 0.513125\nTRAINING --> Epoch: 5/20, Step: 100/180, Loss: 1.3210347718000413, Accuracy: 0.5025\nTRAINING --> Epoch: 5/20, Step: 150/180, Loss: 1.3246196218331654, Accuracy: 0.5047916666666666\nVALIDATION --> Epoch 5/20 DONE, Avg Loss: 1.318944071067704, Avg Accuracy: 0.5067708333333333\nTRAINING --> Epoch: 6/20, Step: 50/718, Loss: 0.9551702511310577, Accuracy: 0.645\nTRAINING --> Epoch: 6/20, Step: 100/718, Loss: 0.9537868970632553, Accuracy: 0.64625\nTRAINING --> Epoch: 6/20, Step: 150/718, Loss: 0.940936678647995, Accuracy: 0.6545833333333333\nTRAINING --> Epoch: 6/20, Step: 200/718, Loss: 0.9387716341018677, Accuracy: 0.651875\nTRAINING --> Epoch: 6/20, Step: 250/718, Loss: 0.9351686859130859, Accuracy: 0.650625\nTRAINING --> Epoch: 6/20, Step: 300/718, Loss: 0.9433725845813751, Accuracy: 0.6483333333333333\nTRAINING --> Epoch: 6/20, Step: 350/718, Loss: 0.9394967205183846, Accuracy: 0.6514285714285715\nTRAINING --> Epoch: 6/20, Step: 400/718, Loss: 0.9367449378967285, Accuracy: 0.65171875\nTRAINING --> Epoch: 6/20, Step: 450/718, Loss: 0.9405326328012679, Accuracy: 0.6498611111111111\nTRAINING --> Epoch: 6/20, Step: 500/718, Loss: 0.9372118552923202, Accuracy: 0.6524375\nTRAINING --> Epoch: 6/20, Step: 550/718, Loss: 0.9383005461909554, Accuracy: 0.6522159090909091\nTRAINING --> Epoch: 6/20, Step: 600/718, Loss: 0.9341262710094452, Accuracy: 0.6525\nTRAINING --> Epoch: 6/20, Step: 650/718, Loss: 0.9344483195818387, Accuracy: 0.6525\nTRAINING --> Epoch: 6/20, Step: 700/718, Loss: 0.9366204073599407, Accuracy: 0.6509821428571428\nTRAINING --> Epoch 6/20 DONE, Avg Loss: 0.9364199524636388, Avg Accuracy: 0.6507698013806468\nTRAINING --> Epoch: 6/20, Step: 50/180, Loss: 1.3222824656963348, Accuracy: 0.535\nTRAINING --> Epoch: 6/20, Step: 100/180, Loss: 1.3347556227445603, Accuracy: 0.5296875\nTRAINING --> Epoch: 6/20, Step: 150/180, Loss: 1.3376802881558736, Accuracy: 0.529375\nVALIDATION --> Epoch 6/20 DONE, Avg Loss: 1.3358668307463328, Avg Accuracy: 0.5280753968253968\nTRAINING --> Epoch: 7/20, Step: 50/718, Loss: 0.7474389785528183, Accuracy: 0.730625\nTRAINING --> Epoch: 7/20, Step: 100/718, Loss: 0.774112882912159, Accuracy: 0.715\nTRAINING --> Epoch: 7/20, Step: 150/718, Loss: 0.7866537775595983, Accuracy: 0.7135416666666666\nTRAINING --> Epoch: 7/20, Step: 200/718, Loss: 0.790848272293806, Accuracy: 0.7084375\nTRAINING --> Epoch: 7/20, Step: 250/718, Loss: 0.7942996710538864, Accuracy: 0.7055\nTRAINING --> Epoch: 7/20, Step: 300/718, Loss: 0.7967072710394859, Accuracy: 0.7038541666666667\nTRAINING --> Epoch: 7/20, Step: 350/718, Loss: 0.8008242343153272, Accuracy: 0.7024107142857143\nTRAINING --> Epoch: 7/20, Step: 400/718, Loss: 0.8034782702475787, Accuracy: 0.70171875\nTRAINING --> Epoch: 7/20, Step: 450/718, Loss: 0.80336075855626, Accuracy: 0.7011111111111111\nTRAINING --> Epoch: 7/20, Step: 500/718, Loss: 0.8085756251215934, Accuracy: 0.6993125\nTRAINING --> Epoch: 7/20, Step: 550/718, Loss: 0.8136892061341893, Accuracy: 0.6977840909090909\nTRAINING --> Epoch: 7/20, Step: 600/718, Loss: 0.8159699020783107, Accuracy: 0.6981770833333333\nTRAINING --> Epoch: 7/20, Step: 650/718, Loss: 0.8218017416733961, Accuracy: 0.6960576923076923\nTRAINING --> Epoch: 7/20, Step: 700/718, Loss: 0.8254714695044926, Accuracy: 0.6947767857142857\nTRAINING --> Epoch 7/20 DONE, Avg Loss: 0.826337409135691, Avg Accuracy: 0.6943975566186267\nTRAINING --> Epoch: 7/20, Step: 50/180, Loss: 1.3913307142257691, Accuracy: 0.52375\nTRAINING --> Epoch: 7/20, Step: 100/180, Loss: 1.350347648859024, Accuracy: 0.5346875\nTRAINING --> Epoch: 7/20, Step: 150/180, Loss: 1.3513408410549164, Accuracy: 0.5391666666666667\nVALIDATION --> Epoch 7/20 DONE, Avg Loss: 1.3644472036096784, Avg Accuracy: 0.534375\nTRAINING --> Epoch: 8/20, Step: 50/718, Loss: 0.6732789689302444, Accuracy: 0.750625\nTRAINING --> Epoch: 8/20, Step: 100/718, Loss: 0.6866803282499313, Accuracy: 0.73875\nTRAINING --> Epoch: 8/20, Step: 150/718, Loss: 0.6732024333874385, Accuracy: 0.7447916666666666\nTRAINING --> Epoch: 8/20, Step: 200/718, Loss: 0.6752755577862263, Accuracy: 0.74875\nTRAINING --> Epoch: 8/20, Step: 250/718, Loss: 0.6962491861581802, Accuracy: 0.739875\nTRAINING --> Epoch: 8/20, Step: 300/718, Loss: 0.7018371114134788, Accuracy: 0.7377083333333333\nTRAINING --> Epoch: 8/20, Step: 350/718, Loss: 0.7064464748757227, Accuracy: 0.7366071428571429\nTRAINING --> Epoch: 8/20, Step: 400/718, Loss: 0.7103659794479609, Accuracy: 0.735390625\nTRAINING --> Epoch: 8/20, Step: 450/718, Loss: 0.7146866464614868, Accuracy: 0.7335416666666666\nTRAINING --> Epoch: 8/20, Step: 500/718, Loss: 0.7185006694793701, Accuracy: 0.7310625\nTRAINING --> Epoch: 8/20, Step: 550/718, Loss: 0.7252128348025408, Accuracy: 0.7291477272727273\nTRAINING --> Epoch: 8/20, Step: 600/718, Loss: 0.729381604741017, Accuracy: 0.728125\nTRAINING --> Epoch: 8/20, Step: 650/718, Loss: 0.7323581333343799, Accuracy: 0.7274038461538461\nTRAINING --> Epoch: 8/20, Step: 700/718, Loss: 0.7389100586090769, Accuracy: 0.7248660714285714\nTRAINING --> Epoch 8/20 DONE, Avg Loss: 0.738577532984088, Avg Accuracy: 0.7247411287392516\nTRAINING --> Epoch: 8/20, Step: 50/180, Loss: 1.402282817363739, Accuracy: 0.538125\nTRAINING --> Epoch: 8/20, Step: 100/180, Loss: 1.3942500710487367, Accuracy: 0.541875\nTRAINING --> Epoch: 8/20, Step: 150/180, Loss: 1.3797748589515686, Accuracy: 0.5458333333333333\nVALIDATION --> Epoch 8/20 DONE, Avg Loss: 1.3779133750332726, Avg Accuracy: 0.5456597222222223\nTRAINING --> Epoch: 9/20, Step: 50/718, Loss: 0.5973920810222626, Accuracy: 0.789375\nTRAINING --> Epoch: 9/20, Step: 100/718, Loss: 0.5771841466426849, Accuracy: 0.793125\nTRAINING --> Epoch: 9/20, Step: 150/718, Loss: 0.5742149227857589, Accuracy: 0.7933333333333333\nTRAINING --> Epoch: 9/20, Step: 200/718, Loss: 0.578166426718235, Accuracy: 0.7915625\nTRAINING --> Epoch: 9/20, Step: 250/718, Loss: 0.5884034839868546, Accuracy: 0.785\nTRAINING --> Epoch: 9/20, Step: 300/718, Loss: 0.6033181443810463, Accuracy: 0.7788541666666666\nTRAINING --> Epoch: 9/20, Step: 350/718, Loss: 0.6164953054700579, Accuracy: 0.773125\nTRAINING --> Epoch: 9/20, Step: 400/718, Loss: 0.6302589143812657, Accuracy: 0.76734375\nTRAINING --> Epoch: 9/20, Step: 450/718, Loss: 0.6375908772812949, Accuracy: 0.7638194444444445\nTRAINING --> Epoch: 9/20, Step: 500/718, Loss: 0.6446969029903412, Accuracy: 0.7611875\nTRAINING --> Epoch: 9/20, Step: 550/718, Loss: 0.6508037875457243, Accuracy: 0.7588068181818182\nTRAINING --> Epoch: 9/20, Step: 600/718, Loss: 0.6565786003569762, Accuracy: 0.75640625\nTRAINING --> Epoch: 9/20, Step: 650/718, Loss: 0.6596950479654166, Accuracy: 0.754423076923077\nTRAINING --> Epoch: 9/20, Step: 700/718, Loss: 0.665192582479545, Accuracy: 0.7524107142857143\nTRAINING --> Epoch 9/20 DONE, Avg Loss: 0.6664341188406878, Avg Accuracy: 0.7522045688506722\nTRAINING --> Epoch: 9/20, Step: 50/180, Loss: 1.6337572503089905, Accuracy: 0.53\nTRAINING --> Epoch: 9/20, Step: 100/180, Loss: 1.6086811077594758, Accuracy: 0.52375\nTRAINING --> Epoch: 9/20, Step: 150/180, Loss: 1.6204711234569549, Accuracy: 0.5239583333333333\nVALIDATION --> Epoch 9/20 DONE, Avg Loss: 1.6184420843919118, Avg Accuracy: 0.5266617063492063\nTRAINING --> Epoch: 10/20, Step: 50/718, Loss: 0.5445287552475929, Accuracy: 0.79625\nTRAINING --> Epoch: 10/20, Step: 100/718, Loss: 0.5290309654176235, Accuracy: 0.8\nTRAINING --> Epoch: 10/20, Step: 150/718, Loss: 0.5245504342516263, Accuracy: 0.8039583333333333\nTRAINING --> Epoch: 10/20, Step: 200/718, Loss: 0.5290844482928514, Accuracy: 0.8021875\nTRAINING --> Epoch: 10/20, Step: 250/718, Loss: 0.5413451755642891, Accuracy: 0.79875\nTRAINING --> Epoch: 10/20, Step: 300/718, Loss: 0.5523241088291009, Accuracy: 0.7946875\nTRAINING --> Epoch: 10/20, Step: 350/718, Loss: 0.5586428977336202, Accuracy: 0.7935714285714286\nTRAINING --> Epoch: 10/20, Step: 400/718, Loss: 0.568013877607882, Accuracy: 0.789609375\nTRAINING --> Epoch: 10/20, Step: 450/718, Loss: 0.5772729689213965, Accuracy: 0.7861805555555555\nTRAINING --> Epoch: 10/20, Step: 500/718, Loss: 0.5842420794069767, Accuracy: 0.7843125\nTRAINING --> Epoch: 10/20, Step: 550/718, Loss: 0.5888363706794653, Accuracy: 0.7824431818181818\nTRAINING --> Epoch: 10/20, Step: 600/718, Loss: 0.5935845070332288, Accuracy: 0.78015625\nTRAINING --> Epoch: 10/20, Step: 650/718, Loss: 0.5983217312510197, Accuracy: 0.7793269230769231\nTRAINING --> Epoch: 10/20, Step: 700/718, Loss: 0.6046582456358841, Accuracy: 0.7776785714285714\nTRAINING --> Epoch 10/20 DONE, Avg Loss: 0.6080231049142176, Avg Accuracy: 0.7760555437810343\nTRAINING --> Epoch: 10/20, Step: 50/180, Loss: 1.4310892069339751, Accuracy: 0.525\nTRAINING --> Epoch: 10/20, Step: 100/180, Loss: 1.4615277528762818, Accuracy: 0.53\nTRAINING --> Epoch: 10/20, Step: 150/180, Loss: 1.5028834136327107, Accuracy: 0.525625\nVALIDATION --> Epoch 10/20 DONE, Avg Loss: 1.4964288969834645, Avg Accuracy: 0.5239087301587302\nTRAINING --> Epoch: 11/20, Step: 50/718, Loss: 0.45571401923894883, Accuracy: 0.84\nTRAINING --> Epoch: 11/20, Step: 100/718, Loss: 0.44875012651085855, Accuracy: 0.8403125\nTRAINING --> Epoch: 11/20, Step: 150/718, Loss: 0.4579535497228305, Accuracy: 0.8364583333333333\nTRAINING --> Epoch: 11/20, Step: 200/718, Loss: 0.46532974049448966, Accuracy: 0.83234375\nTRAINING --> Epoch: 11/20, Step: 250/718, Loss: 0.4786043322086334, Accuracy: 0.829\nTRAINING --> Epoch: 11/20, Step: 300/718, Loss: 0.4874485456943512, Accuracy: 0.8229166666666666\nTRAINING --> Epoch: 11/20, Step: 350/718, Loss: 0.4969210695368903, Accuracy: 0.8176785714285715\nTRAINING --> Epoch: 11/20, Step: 400/718, Loss: 0.5028850818425417, Accuracy: 0.816015625\nTRAINING --> Epoch: 11/20, Step: 450/718, Loss: 0.5090614011552599, Accuracy: 0.8128472222222223\nTRAINING --> Epoch: 11/20, Step: 500/718, Loss: 0.5176647077798844, Accuracy: 0.8095\nTRAINING --> Epoch: 11/20, Step: 550/718, Loss: 0.5262304903702303, Accuracy: 0.8063636363636364\nTRAINING --> Epoch: 11/20, Step: 600/718, Loss: 0.534652081678311, Accuracy: 0.80234375\nTRAINING --> Epoch: 11/20, Step: 650/718, Loss: 0.5421838008440458, Accuracy: 0.7997596153846154\nTRAINING --> Epoch: 11/20, Step: 700/718, Loss: 0.5456544368820531, Accuracy: 0.7983928571428571\nTRAINING --> Epoch 11/20 DONE, Avg Loss: 0.5473803853133595, Avg Accuracy: 0.7980955552864236\nTRAINING --> Epoch: 11/20, Step: 50/180, Loss: 1.7639296412467957, Accuracy: 0.494375\nTRAINING --> Epoch: 11/20, Step: 100/180, Loss: 1.7108091449737548, Accuracy: 0.5128125\nTRAINING --> Epoch: 11/20, Step: 150/180, Loss: 1.7375815165042878, Accuracy: 0.51875\nVALIDATION --> Epoch 11/20 DONE, Avg Loss: 1.7429998199144998, Avg Accuracy: 0.5180059523809524\nTRAINING --> Epoch: 12/20, Step: 50/718, Loss: 0.4213213980197906, Accuracy: 0.85375\nTRAINING --> Epoch: 12/20, Step: 100/718, Loss: 0.426701757311821, Accuracy: 0.8428125\nTRAINING --> Epoch: 12/20, Step: 150/718, Loss: 0.4236577934026718, Accuracy: 0.844375\nTRAINING --> Epoch: 12/20, Step: 200/718, Loss: 0.4510168254375458, Accuracy: 0.834375\nTRAINING --> Epoch: 12/20, Step: 250/718, Loss: 0.45380804187059404, Accuracy: 0.83525\nTRAINING --> Epoch: 12/20, Step: 300/718, Loss: 0.45875185400247576, Accuracy: 0.8339583333333334\nTRAINING --> Epoch: 12/20, Step: 350/718, Loss: 0.4659924879670143, Accuracy: 0.8328571428571429\nTRAINING --> Epoch: 12/20, Step: 400/718, Loss: 0.47190589386969806, Accuracy: 0.83046875\nTRAINING --> Epoch: 12/20, Step: 450/718, Loss: 0.4731592360138893, Accuracy: 0.8298611111111112\nTRAINING --> Epoch: 12/20, Step: 500/718, Loss: 0.47469513776898387, Accuracy: 0.82925\nTRAINING --> Epoch: 12/20, Step: 550/718, Loss: 0.48082325572317297, Accuracy: 0.8266477272727273\nTRAINING --> Epoch: 12/20, Step: 600/718, Loss: 0.48629305164019265, Accuracy: 0.82453125\nTRAINING --> Epoch: 12/20, Step: 650/718, Loss: 0.48792728499724314, Accuracy: 0.8225\nTRAINING --> Epoch: 12/20, Step: 700/718, Loss: 0.49601993371333397, Accuracy: 0.8199107142857143\nTRAINING --> Epoch 12/20 DONE, Avg Loss: 0.49801656421180557, Avg Accuracy: 0.8189017651689476\nTRAINING --> Epoch: 12/20, Step: 50/180, Loss: 1.7362132334709168, Accuracy: 0.53625\nTRAINING --> Epoch: 12/20, Step: 100/180, Loss: 1.7387618613243103, Accuracy: 0.53625\nTRAINING --> Epoch: 12/20, Step: 150/180, Loss: 1.7062942532698313, Accuracy: 0.5397916666666667\nVALIDATION --> Epoch 12/20 DONE, Avg Loss: 1.7028603298796547, Avg Accuracy: 0.5411458333333333\nTRAINING --> Epoch: 13/20, Step: 50/718, Loss: 0.405635467171669, Accuracy: 0.86375\nTRAINING --> Epoch: 13/20, Step: 100/718, Loss: 0.4021433641016483, Accuracy: 0.860625\nTRAINING --> Epoch: 13/20, Step: 150/718, Loss: 0.38241694192091624, Accuracy: 0.8647916666666666\nTRAINING --> Epoch: 13/20, Step: 200/718, Loss: 0.38068303614854815, Accuracy: 0.86359375\nTRAINING --> Epoch: 13/20, Step: 250/718, Loss: 0.38832936573028565, Accuracy: 0.86\nTRAINING --> Epoch: 13/20, Step: 300/718, Loss: 0.3951062200963497, Accuracy: 0.8567708333333334\nTRAINING --> Epoch: 13/20, Step: 350/718, Loss: 0.4011732266630445, Accuracy: 0.8545535714285715\nTRAINING --> Epoch: 13/20, Step: 400/718, Loss: 0.4073588672652841, Accuracy: 0.8525\nTRAINING --> Epoch: 13/20, Step: 450/718, Loss: 0.4110559740662575, Accuracy: 0.8502777777777778\nTRAINING --> Epoch: 13/20, Step: 500/718, Loss: 0.41217794418334963, Accuracy: 0.8499375\nTRAINING --> Epoch: 13/20, Step: 550/718, Loss: 0.4166063863851807, Accuracy: 0.8489772727272727\nTRAINING --> Epoch: 13/20, Step: 600/718, Loss: 0.4273913666109244, Accuracy: 0.8455729166666667\nTRAINING --> Epoch: 13/20, Step: 650/718, Loss: 0.43389827723686514, Accuracy: 0.8429807692307693\nTRAINING --> Epoch: 13/20, Step: 700/718, Loss: 0.43689150940094673, Accuracy: 0.8412053571428572\nTRAINING --> Epoch 13/20 DONE, Avg Loss: 0.44004648925949275, Avg Accuracy: 0.8398782850914375\nTRAINING --> Epoch: 13/20, Step: 50/180, Loss: 1.8170922541618346, Accuracy: 0.52625\nTRAINING --> Epoch: 13/20, Step: 100/180, Loss: 1.839312698841095, Accuracy: 0.52625\nTRAINING --> Epoch: 13/20, Step: 150/180, Loss: 1.8549847098191579, Accuracy: 0.5197916666666667\nVALIDATION --> Epoch 13/20 DONE, Avg Loss: 1.8462652752796809, Avg Accuracy: 0.5198412698412699\nTRAINING --> Epoch: 14/20, Step: 50/718, Loss: 0.3831214100122452, Accuracy: 0.873125\nTRAINING --> Epoch: 14/20, Step: 100/718, Loss: 0.34609739780426024, Accuracy: 0.881875\nTRAINING --> Epoch: 14/20, Step: 150/718, Loss: 0.3523521008094152, Accuracy: 0.87625\nTRAINING --> Epoch: 14/20, Step: 200/718, Loss: 0.3516429688036442, Accuracy: 0.87609375\nTRAINING --> Epoch: 14/20, Step: 250/718, Loss: 0.3544337265789509, Accuracy: 0.875125\nTRAINING --> Epoch: 14/20, Step: 300/718, Loss: 0.35646112290521464, Accuracy: 0.875\nTRAINING --> Epoch: 14/20, Step: 350/718, Loss: 0.35903635346463747, Accuracy: 0.8741964285714285\nTRAINING --> Epoch: 14/20, Step: 400/718, Loss: 0.36339604379609225, Accuracy: 0.87140625\nTRAINING --> Epoch: 14/20, Step: 450/718, Loss: 0.3691742906471093, Accuracy: 0.8691666666666666\nTRAINING --> Epoch: 14/20, Step: 500/718, Loss: 0.37584203150868417, Accuracy: 0.8664375\nTRAINING --> Epoch: 14/20, Step: 550/718, Loss: 0.383763397092169, Accuracy: 0.862840909090909\nTRAINING --> Epoch: 14/20, Step: 600/718, Loss: 0.38826186505456767, Accuracy: 0.8606770833333334\nTRAINING --> Epoch: 14/20, Step: 650/718, Loss: 0.39230588452174114, Accuracy: 0.8586057692307693\nTRAINING --> Epoch: 14/20, Step: 700/718, Loss: 0.39790624720709666, Accuracy: 0.8567410714285715\nTRAINING --> Epoch 14/20 DONE, Avg Loss: 0.3982181179863829, Avg Accuracy: 0.8563472659561584\nTRAINING --> Epoch: 14/20, Step: 50/180, Loss: 1.9394593703746796, Accuracy: 0.5075\nTRAINING --> Epoch: 14/20, Step: 100/180, Loss: 1.9361396092176437, Accuracy: 0.513125\nTRAINING --> Epoch: 14/20, Step: 150/180, Loss: 1.9497579181194304, Accuracy: 0.5185416666666667\nVALIDATION --> Epoch 14/20 DONE, Avg Loss: 1.9311222679085203, Avg Accuracy: 0.5228174603174603\nTRAINING --> Epoch: 15/20, Step: 50/718, Loss: 0.31835096806287766, Accuracy: 0.88375\nTRAINING --> Epoch: 15/20, Step: 100/718, Loss: 0.3064934528619051, Accuracy: 0.889375\nTRAINING --> Epoch: 15/20, Step: 150/718, Loss: 0.30808684080839155, Accuracy: 0.8897916666666666\nTRAINING --> Epoch: 15/20, Step: 200/718, Loss: 0.30601640440523625, Accuracy: 0.8903125\nTRAINING --> Epoch: 15/20, Step: 250/718, Loss: 0.3131873514056206, Accuracy: 0.88775\nTRAINING --> Epoch: 15/20, Step: 300/718, Loss: 0.32350547035535177, Accuracy: 0.885625\nTRAINING --> Epoch: 15/20, Step: 350/718, Loss: 0.33194395090852463, Accuracy: 0.8822321428571429\nTRAINING --> Epoch: 15/20, Step: 400/718, Loss: 0.3348500931449234, Accuracy: 0.881953125\nTRAINING --> Epoch: 15/20, Step: 450/718, Loss: 0.3434676156606939, Accuracy: 0.8784722222222222\nTRAINING --> Epoch: 15/20, Step: 500/718, Loss: 0.3491887545734644, Accuracy: 0.8764375\nTRAINING --> Epoch: 15/20, Step: 550/718, Loss: 0.35620498672127726, Accuracy: 0.8742613636363636\nTRAINING --> Epoch: 15/20, Step: 600/718, Loss: 0.3612611368546883, Accuracy: 0.8725520833333333\nTRAINING --> Epoch: 15/20, Step: 650/718, Loss: 0.36429889534528437, Accuracy: 0.8709615384615385\nTRAINING --> Epoch: 15/20, Step: 700/718, Loss: 0.3658745810389519, Accuracy: 0.8702678571428571\nTRAINING --> Epoch 15/20 DONE, Avg Loss: 0.3670906253096785, Avg Accuracy: 0.8697355274312704\nTRAINING --> Epoch: 15/20, Step: 50/180, Loss: 1.9589691042900086, Accuracy: 0.549375\nTRAINING --> Epoch: 15/20, Step: 100/180, Loss: 1.9556737971305846, Accuracy: 0.54\nTRAINING --> Epoch: 15/20, Step: 150/180, Loss: 1.929579220612844, Accuracy: 0.5416666666666666\nVALIDATION --> Epoch 15/20 DONE, Avg Loss: 1.911551672882504, Avg Accuracy: 0.5437996031746032\nTRAINING --> Epoch: 16/20, Step: 50/718, Loss: 0.24347639061510562, Accuracy: 0.91125\nTRAINING --> Epoch: 16/20, Step: 100/718, Loss: 0.2824124738946557, Accuracy: 0.895\nTRAINING --> Epoch: 16/20, Step: 150/718, Loss: 0.2756797828525305, Accuracy: 0.8985416666666667\nTRAINING --> Epoch: 16/20, Step: 200/718, Loss: 0.2786437871493399, Accuracy: 0.8990625\nTRAINING --> Epoch: 16/20, Step: 250/718, Loss: 0.2779632886201143, Accuracy: 0.90075\nTRAINING --> Epoch: 16/20, Step: 300/718, Loss: 0.28252907933046423, Accuracy: 0.8986458333333334\nTRAINING --> Epoch: 16/20, Step: 350/718, Loss: 0.2915173648297787, Accuracy: 0.8949107142857143\nTRAINING --> Epoch: 16/20, Step: 400/718, Loss: 0.29881657514721155, Accuracy: 0.89125\nTRAINING --> Epoch: 16/20, Step: 450/718, Loss: 0.298477342037691, Accuracy: 0.8909027777777778\nTRAINING --> Epoch: 16/20, Step: 500/718, Loss: 0.3044279340133071, Accuracy: 0.889\nTRAINING --> Epoch: 16/20, Step: 550/718, Loss: 0.3074191329899159, Accuracy: 0.8884659090909091\nTRAINING --> Epoch: 16/20, Step: 600/718, Loss: 0.3085667192501326, Accuracy: 0.8876041666666666\nTRAINING --> Epoch: 16/20, Step: 650/718, Loss: 0.3149766770291787, Accuracy: 0.8847596153846153\nTRAINING --> Epoch: 16/20, Step: 700/718, Loss: 0.31677769024989433, Accuracy: 0.8838392857142857\nTRAINING --> Epoch 16/20 DONE, Avg Loss: 0.3180035484129755, Avg Accuracy: 0.8832884219450163\nTRAINING --> Epoch: 16/20, Step: 50/180, Loss: 2.0096458840370177, Accuracy: 0.541875\nTRAINING --> Epoch: 16/20, Step: 100/180, Loss: 2.0109119808673857, Accuracy: 0.5459375\nTRAINING --> Epoch: 16/20, Step: 150/180, Loss: 2.0150748332341513, Accuracy: 0.5460416666666666\nVALIDATION --> Epoch 16/20 DONE, Avg Loss: 2.005952935086356, Avg Accuracy: 0.5472470238095238\nTRAINING --> Epoch: 17/20, Step: 50/718, Loss: 0.22677795238792897, Accuracy: 0.92375\nTRAINING --> Epoch: 17/20, Step: 100/718, Loss: 0.23021530468016863, Accuracy: 0.923125\nTRAINING --> Epoch: 17/20, Step: 150/718, Loss: 0.23441165290772914, Accuracy: 0.9191666666666667\nTRAINING --> Epoch: 17/20, Step: 200/718, Loss: 0.23742958711460233, Accuracy: 0.91765625\nTRAINING --> Epoch: 17/20, Step: 250/718, Loss: 0.2388733953386545, Accuracy: 0.9165\nTRAINING --> Epoch: 17/20, Step: 300/718, Loss: 0.24376092420270046, Accuracy: 0.9138541666666666\nTRAINING --> Epoch: 17/20, Step: 350/718, Loss: 0.2523297332120793, Accuracy: 0.9103571428571429\nTRAINING --> Epoch: 17/20, Step: 400/718, Loss: 0.2594309094641358, Accuracy: 0.90703125\nTRAINING --> Epoch: 17/20, Step: 450/718, Loss: 0.2669273890140984, Accuracy: 0.905\nTRAINING --> Epoch: 17/20, Step: 500/718, Loss: 0.27487861637026073, Accuracy: 0.901625\nTRAINING --> Epoch: 17/20, Step: 550/718, Loss: 0.27611102420498024, Accuracy: 0.9015340909090909\nTRAINING --> Epoch: 17/20, Step: 600/718, Loss: 0.28176106087242564, Accuracy: 0.89984375\nTRAINING --> Epoch: 17/20, Step: 650/718, Loss: 0.2863126960454079, Accuracy: 0.8981730769230769\nTRAINING --> Epoch: 17/20, Step: 700/718, Loss: 0.2911796050146222, Accuracy: 0.8960267857142857\nTRAINING --> Epoch 17/20 DONE, Avg Loss: 0.29048560677526886, Avg Accuracy: 0.896222523313552\nTRAINING --> Epoch: 17/20, Step: 50/180, Loss: 1.96619903922081, Accuracy: 0.558125\nTRAINING --> Epoch: 17/20, Step: 100/180, Loss: 1.9137354558706283, Accuracy: 0.564375\nTRAINING --> Epoch: 17/20, Step: 150/180, Loss: 1.916152229309082, Accuracy: 0.5666666666666667\nVALIDATION --> Epoch 17/20 DONE, Avg Loss: 1.9150346365239885, Avg Accuracy: 0.5639632936507937\nTRAINING --> Epoch: 18/20, Step: 50/718, Loss: 0.1952989286184311, Accuracy: 0.929375\nTRAINING --> Epoch: 18/20, Step: 100/718, Loss: 0.20278288044035434, Accuracy: 0.9290625\nTRAINING --> Epoch: 18/20, Step: 150/718, Loss: 0.20631225099166234, Accuracy: 0.9270833333333334\nTRAINING --> Epoch: 18/20, Step: 200/718, Loss: 0.2105534435622394, Accuracy: 0.92484375\nTRAINING --> Epoch: 18/20, Step: 250/718, Loss: 0.22242229114472867, Accuracy: 0.92\nTRAINING --> Epoch: 18/20, Step: 300/718, Loss: 0.2246830994511644, Accuracy: 0.9195833333333333\nTRAINING --> Epoch: 18/20, Step: 350/718, Loss: 0.23337717408580438, Accuracy: 0.9159821428571429\nTRAINING --> Epoch: 18/20, Step: 400/718, Loss: 0.2395120541099459, Accuracy: 0.914296875\nTRAINING --> Epoch: 18/20, Step: 450/718, Loss: 0.24438425213926368, Accuracy: 0.9134027777777778\nTRAINING --> Epoch: 18/20, Step: 500/718, Loss: 0.25132577926665545, Accuracy: 0.9111875\nTRAINING --> Epoch: 18/20, Step: 550/718, Loss: 0.2536290351978757, Accuracy: 0.9104545454545454\nTRAINING --> Epoch: 18/20, Step: 600/718, Loss: 0.2585237083149453, Accuracy: 0.9082291666666666\nTRAINING --> Epoch: 18/20, Step: 650/718, Loss: 0.26445167190180374, Accuracy: 0.906298076923077\nTRAINING --> Epoch: 18/20, Step: 700/718, Loss: 0.26971614997833965, Accuracy: 0.9041964285714286\nTRAINING --> Epoch 18/20 DONE, Avg Loss: 0.2733729698832736, Avg Accuracy: 0.9029516622259901\nTRAINING --> Epoch: 18/20, Step: 50/180, Loss: 1.974031686782837, Accuracy: 0.574375\nTRAINING --> Epoch: 18/20, Step: 100/180, Loss: 2.0869459635019303, Accuracy: 0.5578125\nTRAINING --> Epoch: 18/20, Step: 150/180, Loss: 2.0831783457597095, Accuracy: 0.55625\nVALIDATION --> Epoch 18/20 DONE, Avg Loss: 2.0889709257417257, Avg Accuracy: 0.5580357142857143\nTRAINING --> Epoch: 19/20, Step: 50/718, Loss: 0.23209111772477628, Accuracy: 0.924375\nTRAINING --> Epoch: 19/20, Step: 100/718, Loss: 0.2175103912129998, Accuracy: 0.9290625\nTRAINING --> Epoch: 19/20, Step: 150/718, Loss: 0.20931891232728958, Accuracy: 0.930625\nTRAINING --> Epoch: 19/20, Step: 200/718, Loss: 0.20734183022752403, Accuracy: 0.92875\nTRAINING --> Epoch: 19/20, Step: 250/718, Loss: 0.21292202143371106, Accuracy: 0.92575\nTRAINING --> Epoch: 19/20, Step: 300/718, Loss: 0.2151282982279857, Accuracy: 0.9253125\nTRAINING --> Epoch: 19/20, Step: 350/718, Loss: 0.2199569243086236, Accuracy: 0.9233928571428571\nTRAINING --> Epoch: 19/20, Step: 400/718, Loss: 0.2268954597879201, Accuracy: 0.921015625\nTRAINING --> Epoch: 19/20, Step: 450/718, Loss: 0.23313466943800448, Accuracy: 0.9180555555555555\nTRAINING --> Epoch: 19/20, Step: 500/718, Loss: 0.23741337966173887, Accuracy: 0.9155625\nTRAINING --> Epoch: 19/20, Step: 550/718, Loss: 0.2390412514521317, Accuracy: 0.9151136363636364\nTRAINING --> Epoch: 19/20, Step: 600/718, Loss: 0.23981506820147236, Accuracy: 0.9144791666666666\nTRAINING --> Epoch: 19/20, Step: 650/718, Loss: 0.2463929794671444, Accuracy: 0.911875\nTRAINING --> Epoch: 19/20, Step: 700/718, Loss: 0.2513039736715811, Accuracy: 0.9097321428571429\nTRAINING --> Epoch 19/20 DONE, Avg Loss: 0.2535423159775711, Avg Accuracy: 0.9092550260385127\nTRAINING --> Epoch: 19/20, Step: 50/180, Loss: 2.016930515766144, Accuracy: 0.556875\nTRAINING --> Epoch: 19/20, Step: 100/180, Loss: 2.1124969696998597, Accuracy: 0.5459375\nTRAINING --> Epoch: 19/20, Step: 150/180, Loss: 2.1090356802940367, Accuracy: 0.5489583333333333\nVALIDATION --> Epoch 19/20 DONE, Avg Loss: 2.1169701698753567, Avg Accuracy: 0.5458829365079365\nTRAINING --> Epoch: 20/20, Step: 50/718, Loss: 0.18714812472462655, Accuracy: 0.933125\nTRAINING --> Epoch: 20/20, Step: 100/718, Loss: 0.18386089622974397, Accuracy: 0.93375\nTRAINING --> Epoch: 20/20, Step: 150/718, Loss: 0.18729212400813897, Accuracy: 0.933125\nTRAINING --> Epoch: 20/20, Step: 200/718, Loss: 0.1809315516985953, Accuracy: 0.93671875\nTRAINING --> Epoch: 20/20, Step: 250/718, Loss: 0.1848838848695159, Accuracy: 0.934625\nTRAINING --> Epoch: 20/20, Step: 300/718, Loss: 0.18944646256044506, Accuracy: 0.9314583333333334\nTRAINING --> Epoch: 20/20, Step: 350/718, Loss: 0.19461683796452625, Accuracy: 0.9299107142857143\nTRAINING --> Epoch: 20/20, Step: 400/718, Loss: 0.19757044394966214, Accuracy: 0.927890625\nTRAINING --> Epoch: 20/20, Step: 450/718, Loss: 0.2007148524166809, Accuracy: 0.9266666666666666\nTRAINING --> Epoch: 20/20, Step: 500/718, Loss: 0.204481615036726, Accuracy: 0.925875\nTRAINING --> Epoch: 20/20, Step: 550/718, Loss: 0.21068251852284778, Accuracy: 0.9244318181818182\nTRAINING --> Epoch: 20/20, Step: 600/718, Loss: 0.21395032960921526, Accuracy: 0.9232291666666667\nTRAINING --> Epoch: 20/20, Step: 650/718, Loss: 0.21788296875472252, Accuracy: 0.9215865384615385\nTRAINING --> Epoch: 20/20, Step: 700/718, Loss: 0.2227514297887683, Accuracy: 0.9199553571428571\nTRAINING --> Epoch 20/20 DONE, Avg Loss: 0.2238437971644996, Avg Accuracy: 0.9193695500787211\nTRAINING --> Epoch: 20/20, Step: 50/180, Loss: 2.0894034576416014, Accuracy: 0.573125\nTRAINING --> Epoch: 20/20, Step: 100/180, Loss: 2.1061390537023543, Accuracy: 0.573125\nTRAINING --> Epoch: 20/20, Step: 150/180, Loss: 2.1401731328169507, Accuracy: 0.5697916666666667\nVALIDATION --> Epoch 20/20 DONE, Avg Loss: 2.160762264000045, Avg Accuracy: 0.5658482142857143\nBest Validation Loss: 1.2301086044973797 after epoch 4\nBest Validation Acc: 0.5658482142857143 after epoch 20\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"# TODO: plot train vs validation loss\n# TODO: plot train vs validation accuracy","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-02T20:57:50.447126Z","iopub.execute_input":"2025-06-02T20:57:50.447469Z","iopub.status.idle":"2025-06-02T20:57:50.451191Z","shell.execute_reply.started":"2025-06-02T20:57:50.447432Z","shell.execute_reply":"2025-06-02T20:57:50.450451Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"# TODO: evaluate function (test data)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-02T20:57:50.452530Z","iopub.execute_input":"2025-06-02T20:57:50.452726Z","iopub.status.idle":"2025-06-02T20:57:50.474720Z","shell.execute_reply.started":"2025-06-02T20:57:50.452710Z","shell.execute_reply":"2025-06-02T20:57:50.474206Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"# TODO: run evaluation (test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-02T20:57:50.475420Z","iopub.execute_input":"2025-06-02T20:57:50.475709Z","iopub.status.idle":"2025-06-02T20:57:50.494102Z","shell.execute_reply.started":"2025-06-02T20:57:50.475693Z","shell.execute_reply":"2025-06-02T20:57:50.493602Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"# TODO: export to ONNX","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-02T20:57:50.494787Z","iopub.execute_input":"2025-06-02T20:57:50.494977Z","iopub.status.idle":"2025-06-02T20:57:50.514335Z","shell.execute_reply.started":"2025-06-02T20:57:50.494963Z","shell.execute_reply":"2025-06-02T20:57:50.513806Z"}},"outputs":[],"execution_count":21}]}